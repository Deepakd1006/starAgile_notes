Aws cloud 

5 Aspects or 5 Pillars of the Framework of manage services of AWS 

Highly availability 
Highly Scalability 
Cost-effectiveness
secure 
performance

3 types of computing models are Paas,Iaas, Saas


--------------------------------------
> IAM (Identity and Access Management) 
--------------------------------------

. Costume policy are also called inline policies


.    what is role or what is IAM role ? 
ans: basically giving access to the service to access an other service we use role in aws. most of the time, lets say 80% of the time its for giving permissions for services.
In short, an IAM role is a secure, permission-based access rule for AWS resources, allowing services to communicate without credentials

Example: Giving Ec2 services to access S3 bucket services.
Let's say you have a web application hosted on an EC2 server that needs to store images in an S3 bucket. Instead of storing login credentials for the S3 bucket directly on the server, you can assign an IAM role to the EC2 instance that grants it access to the S3 bucket. The role will allow the EC2 instance to interact with S3, and the permissions are securely managed by AWS without requiring hard-coded credentials.  

we can also give access to users (" assume role" when giving access to a user for a particular time. )
IAM roles are commonly used to grant temporary or cross-account access to users.

Example: 
Account A (your company's primary account)
Account B (another account for a project or a partner)
If a user in Account A needs access to an S3 bucket in Account B, you can set up a role in Account B that allows access to the bucket. The user in Account A can then "assume" this role, getting the permissions needed to interact with the bucket temporarily.


. MFA (Multi-factor authentication) is nothing but setting a two step verification for loging-in to a IAM users. 


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


-----------------------------
> EC2(Elastic Compute Cloud)
-----------------------------


. what are the different types of EC2 ? what are there families ?
Some of this are the examples for the types of EC2 systems based on there performance 

General Purpose
Compute Optimized
Memory Optimized
Storage Optimized
Accelerated Computing
High Performance Computing (HPC)

different types of purchasing 

Dedicated Hosts - costly 
On-Demand Instances 
spot instances - cheapest one
savings plans 
reserved instances



. We can copy the snapshots from one region to other region to transfer data to a different region. we can not attach volume from a different region or AZ to a EC2 instance with different AZ. so we use copy snapshot method. 

. volume which is created in different AZ or region can not be attached to a EC2 instance who's AZ is different. 

. we can automate the back-up of data using snapshot there a option called create snapshot lifecycle policy.  

. Check class recording for more details on instance punches (like On-demand its like pay-as-u-go charged for hrs / Reserved Instances its like a pre-paid plain / Spot Requests is like when there is sale in the AWS market but production does not use this as there is a catch behind like charges change every 1hr or something like that it can be used for the temp use like testing or practices etc) 


AMI(Amazon Machine Images) : Taking the back-up of the EC2 machine we use AMI
Note: while creating the AMI it will also ask a option to take a snapshot of the EBS(elastic block storage) which is attached to the EC2. so snapshot of this ec2 is also stored in the snapshot list. There is a option to disable it as well and create only the Ec2 config machine.

Placement groups: cluster,partition,spread : placing the instance together got better performances we use placement groups with regards to AZ (availability Zones). 

Cluster: In cluster placement group we can only add High performance machines. because we create a placement group for high performance what the point in having low performance machine in it.

Spread and partition  : This two can have low performance 

IP's : elastic IP, (public ip and static ip)


EBS - elastic Block storage 

Three types of EBS volume 
SSD - Solid state drive
HDD - Hard disk drive (HDD) volumes
magnetic 

There is also lifecycle rules to take back-ups for EBS (Automating taking of snapshot for EBS volume)




--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------
EFS (Amazon Elastic File System )
------------------------------------------

Provides a simple, scalable, elastic file system. multiple Ec2 seviers can be attached to the EFS and access it as needed. its acts like a single file system where everyone can use just by connecting to it. 



https://docs.aws.amazon.com/efs/latest/ug/installing-amazon-efs-utils.html#installing-other-distro

https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-mount-helper-ec2-linux.html


############# efs commands #################

sudo yum install -y amazon-efs-utils
sudo mkdir efs	
(choose as per ur efs)-- sudo mount -t efs -o tls fs-0fd6f3deb344d0925:/ efs (changes based on efs created)
(choose as per ur efs)-- sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-0fd6f3deb344d0925.efs.us-east-1.amazonaws.com:/ efs (Changes as per file system)



--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------
S3 Bucket (Amazon Simple Storage Service )
Versioning, Pre-signed URL, website-Hosting, lifecycle rules , replication  Note: S3 is also called bump-home of AWS
-----------------------------------------------------------------------------

If we need to make the bucket public just edit the block all public access "ACL". we should also give access to the data inside the bucket. This means public is private but the objects or data inside the bucket is still private. we sould give them read access or time limited access with the help of "Presigned URL". 

. "Bucker versioning" : If u update the files with the same name it would replace the file. To save the different versions of the file or folders we Turn of a settings called "Bucker versioning" after enabling we can the see the different versions of the files with the same name.

. "Presigned URL" : Giving access to the files to outsider for the minimum time limit for example ur giving demo to a outside clint or something. there is a option called "Presigned URL" which can be used.

. "Hosting static websites in S3" : we can also host static websites in the S3 bucket. Even if we hosting the website of the static files. we need to give access to the html file or all files and folders there read permissions. 3 steps permissions.
1) Make bucket public
2) Object Ownership (ACL access control list)
3) Make object public. (check box : read ,read)

. Object Storage class 
S3 is famous is because of object storage classes, because there we can store files as per there usage. 

Note : There is no storage classes in EBS

In EFS there are : 
1) standard 
2) Infrequent Access
3) Archive mode

In S3 there are:
1) standard
2) Infrequent access(IA): standard IA(Infrequent access) & One-zone IA
3) Archive mode : Glacier, deep-Glacier, Instant Retrieval Glacier. 
4) Intelligent-Tiering (this is completely AI based). 

All of this is called lifecycle management or lifecycle rules : Use lifecycle rules to define actions you want Amazon S3 to take during an object's lifetime such as transitioning objects to another storage class, archiving them, or deleting them after a specified period of time. 
we can create a lifecycle to move the files to a different Storage class as per there usage with days mentioned (The main reason is to reduce the cost)


Replication rules  : WE CAN ALSO HAVE THE REPLICATION OF THE BUCKET.
If your having or create it in same region its called SRR(same region replication) if your want in different region its called CRR(cross-region replication) 


> Encryption 

S3 has a default 1) server-side encryption(SSE) which is free and its done by AWS side. we can also have our own Encryption methods by creating one with the AWS-services called "KMS" Key management system. 
KMS is a separate services so search in the main page. 

2) Dual / client side encryption. 

S3 logs (server access logging) : stores all the log file that the s3 bucket like who accessed what in the bucker its stores all kind of logs like users activates etc.  (more security for S3 KMS)


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


-----------------------------
VPC (Virtual Private Cloud)
-----------------------------

1) Internet-Gateway: In VPC, if users from outside has to entre. it uses internet gateway

2) Subnets(public & private )

. If the subnets are attached to the Internet-gateway than it becomes public.

. The watchman of the subnet is called NACL (network access control list)

. Inside Subnets we have Ec2 instance created as per the requirement. Watchman of the server is called SG ( Security group) 

. Private subnet in order to access internet it uses NAT-gateway

. In order to use an other VPC and if we want to make internal connection its called "VPC peering"

. If we need to access the private server we need to connect them using Public server which is called (bastion host or jump server) we use NAT gateway to give internet to the private subnet and that's how we connect from public server to private server. 

. If showing the route from one subnet to other is called route-table. Connection b/w IGW to public subnet and Connection b/w NAT to private subnets we use route-table. 



Note: when your creating ec2 server inside a VPC with the default SG, we need to edit the SG to allow the inbound rules or else we can not connect to the EC2 server with the web-browser or any SSH clint. 

( SG and NACL in VPC )
. SG works at the EC2 level and NACL is at the subnet level
. There is no deny rule and only allow in SG and NACL has allow and deny 
. In SG we don't work on out-bound rules, whereas in NACL we can also prefer outbound rules. 
. In SG we don't have rule or rank, where as in NACL we have rules and rank. (watch class video 40:00 min/sec to know more about NACL rules and ranks)

> TO KNOW THE WHO COME IN AND WHO GOES OUT OF VPC (to track the data we use "flow log")

flow logs are nothing but it tracks the incoming traffic and stores it in the S3 bucket.

> VPC PEERING 
. Basically connecting two VPC to communicate to each other we use VCP peering.
. We can connect VPC from the same regions, and from different region and different AWS account as well. 
. while connecting a VPC using VPC peering, it just works like a friend request in Facebook we just need to accept or reject

> Direct Connect 
AWS Direct Connect is a dedicated network connection between your on-premises data center (or office) and AWS. It allows you to connect your network to AWS resources privately without using the public internet, offering faster, more reliable, and secure data transfer.


Q&A
1) how many IP's are reserved by AWS ? ---- 5 IP's first 4 and last one.

2) In order to use internet from private server which service is used ? ---- NAT-Gateway. 





--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


---------------------------------------------------------------
Elastic Load Balancer (ELB) its called signal point of contact
---------------------------------------------------------------

Distributes incoming application or network traffic across 
multiple targets, such as Amazon EC2 instances, containers and IP addresses, in 
multiple Availability Zones is called LB. 

AWS offers 4 Load balancers.

> application LB 
> Network LB 
> Gateway LB (new one in market and most of them have no information of it, because its new)
> classic LB (oldest and will be removed sooner or might not as internally all the services use this)

In Common we use  Application Load Balancer and Network Load Balancer. 
During creation we can see "Scheme" like where we want our LB Internet-facing or Internal(Insane like connection FE-servers to DB's etc)

Health check-up 
pinging a website path example : /index.html or localhost/tom-cat or Ip:8080/Jenkins if the  LB can ping check if the application is running in the particular path than the check is successful.  

Step-up 
------------------------------------
1) Working of Classic Load Balance.
------------------------------------
 
1 - Create a LB 
2 - Go inside the LB > under Target-instance(manage instances) select the instance which needs to be attached to this LB. We can add instances while creating only in Classic LB. 

Disturbing the Load
lets say there are EC2 server in two AZ (AZ-1 and AZ-2) Az-1 has 2 severs and Az-2 has 5 Ec2 servers and it is attached to LB. Is it far to if the 80% goes to AZ1 and 20% goes to Az-2 ? No right. We use Cross-zone Load balancing. 
While creating the LB we will have to enable the Cross-zone Load balancing if there EC2 server is in two AZ's and if we need the load to be equally distributed.  

Step-up 
---------------------------------------------
2) Working of ALB- Application Load Balance
---------------------------------------------
Everything is same as Classic Load Balance only difference we will have to create "Target Groups" inside Target group we can add our instance which as same as Classic LB.

Under Listeners and routing while creating we can find or we can create is after creating the LB as well. right-side below the LB we can find Target Groups in there we can create and add instances. 

Note : ALB used (HTTP and HTTPS proto-calls) and NLB used (TCP,TLS and UDP proto-calls)

interview questions 

Difference B/w ALB and NLB (100% conform question) 

ALB - Application LB 
1) it works on 7th layer[app location layer]
2) It works on Domain names (example:google.com)
3) slower
4) side-hosting, content routing, Domain (Example : Google.com > Sub-domain: google News , google image.) 


NLB - Network LB
1) It works on the 4th layer[Transport layer]
2) It works on IP address
3) faster (because it works on IPs)
4) using in Gaming industry, long connation, many number of connections or request are huge we use NLB


interview questions on LB :

1) which type of load balancer works on the network layer ? 
Ans : network load balancer.

2) If the connection has to be on years bases, which kind of LB is to be used ? 
Ans : NLB Net

3) I'm creating a application like amazon.com, which kind of LB is to be used ? 
Ans : Appication LB 


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

----------------------------------------------
AUTO-SCALING 
----------------------------------------------
AWS does not support Vertical Scaling. It supports only Horizontal scaling

There Two types of Scaling. (Google images can give u better understanding so search in Google for more clarity )

1) Vertical Scaling : Increase in size (example: increasing memory or the capacity of a EC2 sever or processor to 64GB to 128GB )

2) Horizontal scaling : Increasing in instance or servers (Basically increasing number of EC2 severs)

> Can we change the type of a EC2 Sever ?
We can change the instance type. But the instance has to be in stop state.  
Steps : Actions > instance settings > Change instance Type. 

example:
So what we just did here is Vertical scaling manually, Lets image Your hosting a cricket match live and we need more powerful system can we stop the server to increase the instance type ? No right. This where horizontal scaling comes into picture which supports auto-scaling.


There are three types of auto-scaling.

1) Predictive scaling policies (Predicted) - AI based AWS sees how we use.  
2) Scheduled actions (Scheduled)  - (Example : Sales like black-Friday we know when we need auto-scaling we can mention the time date etc as per that time the auto scale will scale up and down.) 
3) Dynamic scaling policies (Dynamic) - Which is changing on the requirement. (automatically adjusts resources #can be used in unpredictable situations)


Steps to create auto-scaling.

We need to tell AWS what kind of system we need for auto-scaling. 

step1: We create Auto-Scaling Group.

We need to create a "Launch Template" for auto-scaling.

There are two way we can create Launch template.

First way :  (preferred way)
1) Launch a instance as per-requirement, so here, as we create images for AMI. There is also a option called Create template from instance. 
----------> Actions > image and template >  Create template from instance. 

* Fill in the required details like Launch template name,Template version description, Launch template contents etc 
* Everything here will be picked automatically as we create Template from a existing EC2 instance.

Second way:
2) Under Ec2 > Create launch template towards the lift side u will find. manually creating by providing what type of instance, volume, key-pair, images etc. 

Now under the Auto Scaling > Auto Scaling Groups we can create a Auto-scale for the particular project.

Steps to create: 
1) Choose launch template :  (Give name, select the template ) after selecting the template, we can see what kind of AMI id is used in the template, instance type, key-pair etc. 

2) Choose instance launch options : (Here choose the VPC where the instance has to be create and in which VPC & choose the Availability Zones and subnets) 
In "Availability Zone distribution - new" choose anyone this will Take care of where the instance will be created as per the Availability to create the EC2.

3) Integrate with other services : Here if we want to attach the Load balancer we can do so. we can also create LB if we want here. 
"VPC Lattice integration options" is an additional services that helps us understanding networking. More information about networking so select "No VPC lattice service" here. its an additional services. 
Health check is automatically attached here. 

4)  Configure group size and scaling : 

Note:
Capacity : We have minimum capacity, Desired(normal) capacity & maximum capacity. 

* Here under Configure group size and scaling we can mention our max, min , desired state of the instance (Basically mentioning the number of systems as per the traffic)
* Here we also select the scaling policies. After the creation also we can choose the "scaling policies" There are three policy 

Note: Selecting the Max desired capacity is completely based on the budget of the project. there is no particular calculation for it.  

Explanation of the "scaling policies"

1) Scheduled action : we can set time for creation of the EC2 instance and Deletion of EC2. For both creation and deletion we need to create a Separate action. 
Setting the max, min and Desired state of the EC2. we can also schedule time of creation and deletion. Explore the Service in Aws console for better understanding. 

2) Dynamic scaling policies : Dynamic is divided into 3 sub-category.
we have different Metric : CPU Utilization and Network coming in and out traffic. 
Note: In generally in our industry we focus on CPU Utilization.  

* Target : In target, we can set conduction life lets say (if CPU utilization = 50% increase into max )

* Simple : In Simple the process is almost same but it uses an one addition feature called CloudWatch alarms. ( if load is 70% it increases number of servers ) We should create a cloudwatcg alaram 

* Step-Case : Step-case is like a normal staircase in real life.
( 1st step: if utilization is 50 add 2 servers
  2nd step: if utilization is 60 add 1 more servers
  3rd step: if utilization is 70 add 1 more level servers )
  We should create a cloudwatcg alaram here also. 

Note : In industory we use the first one "trager trackinf scaling" based. 

You can test this policie by putting load on the servers.
The command to put stress on sever is : sudo apt install stress
					sudo stress --cpu 16 



--------------------
Chat-GPT questions.
--------------------
So auto scaling is only about handling traffic ? and system processer types makes the application faster ? am I right ?

Answer: Yes, you're absolutely correct! Auto Scaling is primarily about managing traffic load and ensuring your application has the right number of resources (instances) to handle changes in demand. However, the underlying instance types and system configurations (like processor type, memory, and network performance) determine how efficiently the application runs and how "fast" it feels to users.







     
  



























 







 


































